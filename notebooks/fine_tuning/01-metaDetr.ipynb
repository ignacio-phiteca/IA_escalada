{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO facebook/detr-resnet-50 \n",
    "[facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T21:54:23.990841Z",
     "start_time": "2024-04-04T21:54:16.295372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T21:54:24.569137Z",
     "start_time": "2024-04-04T21:54:23.991320Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nDetrConvEncoder requires the timm library but it was not found in your environment. You can install it with pip:\n`pip install timm`. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# cargamos el modelo y el procesador de imagen\u001b[39;00m\n\u001b[1;32m      4\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoImageProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/detr-resnet-50\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForObjectDetection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/detr-resnet-50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:3404\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3398\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   3399\u001b[0m     config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   3400\u001b[0m )\n\u001b[1;32m   3402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   3403\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 3404\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3406\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/detr/modeling_detr.py:1481\u001b[0m, in \u001b[0;36mDetrForObjectDetection.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;66;03m# DETR encoder-decoder model\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mDetrModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# Object detection heads\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_labels_classifier \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\n\u001b[1;32m   1485\u001b[0m     config\u001b[38;5;241m.\u001b[39md_model, config\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1486\u001b[0m )  \u001b[38;5;66;03m# We add one for the \"no object\" class\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/detr/modeling_detr.py:1313\u001b[0m, in \u001b[0;36mDetrModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m# Create backbone + positional encoding\u001b[39;00m\n\u001b[0;32m-> 1313\u001b[0m backbone \u001b[38;5;241m=\u001b[39m \u001b[43mDetrConvEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1314\u001b[0m object_queries \u001b[38;5;241m=\u001b[39m build_position_encoding(config)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;241m=\u001b[39m DetrConvModel(backbone, object_queries)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/models/detr/modeling_detr.py:351\u001b[0m, in \u001b[0;36mDetrConvEncoder.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muse_timm_backbone:\n\u001b[0;32m--> 351\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdilation:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1400\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1398\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nDetrConvEncoder requires the timm library but it was not found in your environment. You can install it with pip:\n`pip install timm`. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    " # librerias para la autodeteccion del procesador de imagenes y el modelo de deteccion de objetos\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "# cargamos el modelo y el procesador de imagen\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T21:54:24.930248Z",
     "start_time": "2024-04-04T21:54:24.569074Z"
    }
   },
   "outputs": [],
   "source": [
    "# importamos la clase inferencia que he creado en esta ruta /Users/ignaciocarrenoromero/proyecto_escalada/app/utils/inferencia.py\n",
    "import sys\n",
    "sys.path.append('/Users/ignaciocarrenoromero/proyecto_escalada/app/utils')\n",
    "from inferencia import Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T21:54:24.934259Z",
     "start_time": "2024-04-04T21:54:24.931008Z"
    }
   },
   "outputs": [],
   "source": [
    "inferencia = Inferencia(model, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-04T21:54:57.738335Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 23:54:58.000 python[2254:24007] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected airplane with confidence 0.978 at location [6, 3, 1260, 1068]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected bed with confidence 0.913 at location [7, 7, 1378, 638]\n",
      "Detected person with confidence 0.981 at location [1125, 2, 1916, 1063]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.992 at location [591, 589, 743, 742]\n",
      "Detected vase with confidence 0.964 at location [635, 662, 705, 741]\n",
      "Detected cup with confidence 0.947 at location [786, 139, 1059, 295]\n",
      "Detected person with confidence 0.946 at location [576, 1, 1917, 1066]\n",
      "Detected person with confidence 0.902 at location [736, 2, 1916, 1064]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected chair with confidence 0.921 at location [0, 530, 732, 1069]\n",
      "Detected fork with confidence 0.904 at location [438, 144, 937, 307]\n",
      "Detected couch with confidence 0.973 at location [0, 452, 742, 1069]\n",
      "Detected person with confidence 1.0 at location [433, 3, 1762, 1067]\n",
      "Detected cup with confidence 0.997 at location [756, 378, 1102, 614]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.995 at location [386, 605, 571, 763]\n",
      "Detected spoon with confidence 0.993 at location [763, 283, 981, 483]\n",
      "Detected couch with confidence 0.984 at location [0, 498, 633, 1069]\n",
      "Detected person with confidence 1.0 at location [522, 2, 1494, 1066]\n",
      "Detected bowl with confidence 0.997 at location [908, 431, 1180, 613]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected chair with confidence 0.993 at location [-1, 745, 577, 1074]\n",
      "Detected spoon with confidence 0.99 at location [577, 388, 812, 523]\n",
      "Detected bowl with confidence 0.997 at location [728, 459, 995, 643]\n",
      "Detected potted plant with confidence 0.993 at location [350, 601, 462, 756]\n",
      "Detected couch with confidence 0.968 at location [0, 740, 573, 1072]\n",
      "Detected person with confidence 1.0 at location [406, 2, 1331, 1067]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected spoon with confidence 0.922 at location [556, 444, 639, 500]\n",
      "Detected person with confidence 1.0 at location [208, 3, 1199, 1066]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected bowl with confidence 0.97 at location [960, 651, 1209, 818]\n",
      "Detected person with confidence 1.0 at location [619, 2, 1540, 1065]\n",
      "Detected cup with confidence 0.983 at location [966, 655, 1212, 821]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected couch with confidence 0.976 at location [1, 597, 760, 1070]\n",
      "Detected potted plant with confidence 0.996 at location [603, 674, 768, 825]\n",
      "Detected spoon with confidence 0.993 at location [781, 302, 1030, 464]\n",
      "Detected person with confidence 1.0 at location [579, 2, 1496, 1066]\n",
      "Detected bowl with confidence 0.995 at location [931, 423, 1188, 580]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected bowl with confidence 0.966 at location [942, 493, 1171, 634]\n",
      "Detected potted plant with confidence 0.994 at location [665, 695, 803, 844]\n",
      "Detected couch with confidence 0.966 at location [0, 551, 807, 1070]\n",
      "Detected person with confidence 1.0 at location [600, 2, 1491, 1067]\n",
      "Detected cup with confidence 0.985 at location [947, 493, 1171, 635]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.997 at location [694, 774, 859, 914]\n",
      "Detected spoon with confidence 0.994 at location [854, 459, 1068, 571]\n",
      "Detected couch with confidence 0.981 at location [1, 626, 855, 1070]\n",
      "Detected person with confidence 1.0 at location [682, 2, 1531, 1065]\n",
      "Detected bowl with confidence 0.998 at location [981, 542, 1197, 678]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected cake with confidence 0.987 at location [1062, 477, 1153, 516]\n",
      "Detected bowl with confidence 0.943 at location [1004, 500, 1221, 638]\n",
      "Detected potted plant with confidence 0.996 at location [693, 773, 855, 918]\n",
      "Detected spoon with confidence 0.914 at location [856, 394, 1111, 520]\n",
      "Detected couch with confidence 0.95 at location [1, 637, 862, 1069]\n",
      "Detected person with confidence 1.0 at location [678, 2, 1541, 1066]\n",
      "Detected cup with confidence 0.989 at location [1007, 500, 1223, 640]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected person with confidence 0.999 at location [810, 220, 1809, 1067]\n",
      "Detected cake with confidence 0.998 at location [1231, 781, 1491, 970]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected couch with confidence 0.969 at location [0, 560, 1179, 1069]\n",
      "Detected bowl with confidence 0.981 at location [1360, 507, 1593, 669]\n",
      "Detected person with confidence 0.999 at location [989, 17, 1918, 1066]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected person with confidence 0.999 at location [807, 3, 1694, 1067]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.992 at location [771, 752, 886, 889]\n",
      "Detected spoon with confidence 0.987 at location [925, 238, 1156, 339]\n",
      "Detected couch with confidence 0.992 at location [0, 611, 898, 1069]\n",
      "Detected person with confidence 1.0 at location [739, 10, 1516, 1066]\n",
      "Detected cup with confidence 0.988 at location [1051, 361, 1204, 465]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.994 at location [837, 811, 965, 951]\n",
      "Detected cup with confidence 0.997 at location [1127, 451, 1277, 550]\n",
      "Detected cake with confidence 0.935 at location [1177, 360, 1263, 440]\n",
      "Detected couch with confidence 0.992 at location [0, 675, 970, 1070]\n",
      "Detected person with confidence 1.0 at location [823, 84, 1595, 1067]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.919 at location [759, 972, 870, 1079]\n",
      "Detected toothbrush with confidence 0.929 at location [1018, 477, 1129, 562]\n",
      "Detected person with confidence 1.0 at location [725, 235, 1520, 1064]\n",
      "Detected cup with confidence 0.996 at location [1027, 605, 1131, 714]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.993 at location [906, 666, 1024, 802]\n",
      "Detected spoon with confidence 0.964 at location [1113, 142, 1263, 199]\n",
      "Detected couch with confidence 0.99 at location [1, 521, 1026, 1067]\n",
      "Detected person with confidence 1.0 at location [883, 3, 1687, 1068]\n",
      "Detected cup with confidence 0.997 at location [1187, 280, 1341, 388]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.993 at location [892, 630, 1008, 767]\n",
      "Detected cup with confidence 0.995 at location [1164, 242, 1320, 353]\n",
      "Detected couch with confidence 0.987 at location [0, 488, 1009, 1068]\n",
      "Detected person with confidence 1.0 at location [875, 3, 1665, 1067]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.995 at location [880, 576, 989, 712]\n",
      "Detected cell phone with confidence 0.971 at location [1507, 919, 1605, 987]\n",
      "Detected bottle with confidence 0.94 at location [1715, 1024, 1764, 1080]\n",
      "Detected cup with confidence 0.997 at location [1137, 175, 1297, 290]\n",
      "Detected couch with confidence 0.986 at location [0, 433, 1002, 1068]\n",
      "Detected person with confidence 1.0 at location [850, 2, 1649, 1066]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected cup with confidence 0.996 at location [1119, 86, 1274, 200]\n",
      "Detected potted plant with confidence 0.994 at location [854, 515, 965, 655]\n",
      "Detected couch with confidence 0.995 at location [1, 368, 983, 1067]\n",
      "Detected person with confidence 1.0 at location [828, 3, 1639, 1067]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.99 at location [772, 913, 881, 1047]\n",
      "Detected spoon with confidence 0.985 at location [980, 441, 1126, 495]\n",
      "Detected couch with confidence 0.982 at location [0, 770, 644, 1072]\n",
      "Detected person with confidence 1.0 at location [717, 179, 1510, 1066]\n",
      "Detected cup with confidence 0.996 at location [1011, 588, 1148, 691]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected person with confidence 0.999 at location [810, 412, 1568, 1067]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected cake with confidence 0.907 at location [1192, 694, 1263, 750]\n",
      "Detected person with confidence 0.999 at location [884, 437, 1653, 1069]\n",
      "Detected cup with confidence 0.995 at location [1161, 825, 1301, 926]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected cup with confidence 0.993 at location [1069, 695, 1209, 796]\n",
      "Detected spoon with confidence 0.951 at location [1050, 566, 1173, 609]\n",
      "Detected couch with confidence 0.972 at location [0, 889, 644, 1077]\n",
      "Detected person with confidence 1.0 at location [787, 309, 1573, 1068]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected cell phone with confidence 0.966 at location [1396, 973, 1506, 1035]\n",
      "Detected couch with confidence 0.974 at location [0, 482, 925, 1069]\n",
      "Detected person with confidence 1.0 at location [761, 3, 1527, 1066]\n",
      "Detected potted plant with confidence 0.993 at location [815, 615, 911, 751]\n",
      "Detected spoon with confidence 0.977 at location [992, 140, 1142, 185]\n",
      "Detected cup with confidence 0.996 at location [1036, 275, 1179, 385]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected cell phone with confidence 0.929 at location [1404, 970, 1514, 1036]\n",
      "Detected couch with confidence 0.987 at location [0, 483, 920, 1069]\n",
      "Detected person with confidence 1.0 at location [761, 3, 1547, 1066]\n",
      "Detected potted plant with confidence 0.994 at location [808, 620, 909, 757]\n",
      "Detected cup with confidence 0.994 at location [1037, 260, 1178, 370]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected person with confidence 0.991 at location [956, 2, 1738, 1062]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.994 at location [1007, 646, 1145, 791]\n",
      "Detected couch with confidence 0.993 at location [0, 500, 1140, 1068]\n",
      "Detected person with confidence 0.999 at location [1010, 3, 1833, 1068]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected couch with confidence 0.934 at location [4, 310, 1465, 1065]\n",
      "Detected couch with confidence 0.984 at location [3, 267, 1467, 1066]\n",
      "Detected potted plant with confidence 0.998 at location [1217, 423, 1398, 583]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected tv with confidence 0.999 at location [913, 442, 1185, 762]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected couch with confidence 0.993 at location [3, 615, 1394, 1065]\n",
      "Detected potted plant with confidence 0.997 at location [1163, 762, 1337, 922]\n",
      "Detected spoon with confidence 0.994 at location [1525, 287, 1869, 506]\n",
      "Detected person with confidence 0.996 at location [1281, 2, 1918, 1065]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected couch with confidence 0.995 at location [2, 660, 1421, 1068]\n",
      "Detected cup with confidence 0.909 at location [1876, 533, 1919, 653]\n",
      "Detected potted plant with confidence 0.997 at location [1202, 805, 1374, 964]\n",
      "Detected person with confidence 0.995 at location [1447, 3, 1918, 1066]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected person with confidence 0.921 at location [1521, 350, 1919, 1069]\n",
      "Detected potted plant with confidence 0.996 at location [1189, 821, 1370, 980]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected couch with confidence 0.995 at location [0, 627, 1380, 1067]\n",
      "Detected potted plant with confidence 0.998 at location [1154, 775, 1324, 931]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected potted plant with confidence 0.997 at location [767, 823, 947, 984]\n",
      "Detected vase with confidence 0.922 at location [814, 897, 894, 981]\n",
      "Detected cup with confidence 0.976 at location [1457, 497, 1708, 653]\n",
      "Detected bowl with confidence 0.95 at location [1460, 499, 1705, 651]\n",
      "Detected couch with confidence 0.988 at location [0, 678, 986, 1068]\n",
      "Detected person with confidence 0.999 at location [1052, 18, 1917, 1066]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected person with confidence 0.979 at location [1013, 2, 1893, 1064]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "Detected suitcase with confidence 0.948 at location [1024, 181, 1235, 456]\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n",
      "<class 'numpy.ndarray'> (1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "inferencia.inferencia_video_directo(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencia.inferencia_imagen_URL(\"https://static.fundacion-affinity.org/cdn/farfuture/PVbbIC-0M9y4fPbbCsdvAD8bcjjtbFc0NSP3lRwlWcE/mtime:1643275542/sites/default/files/los-10-sonidos-principales-del-perro.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
